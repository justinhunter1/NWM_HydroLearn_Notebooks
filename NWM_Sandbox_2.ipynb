{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the National Water Model (NWM) Sandbox 2! \n",
    "\n",
    "<strong><em>Created by <a href=\"https://www.linkedin.com/in/justin-hunter-0b86871a6/\" target=\"_blank\">Justin Hunter</a>, <a href=\"https://www.linkedin.com/in/danames/\" target=\"_blank\">Dr. Dan Ames</a>, and <a href=\"https://www.linkedin.com/in/easton-perkins-02968a156/\" target=\"_blank\">Easton Perkins</a>.</em></strong><br>\n",
    "<em><strong>June, 2021. Brigham Young University. Provo, Utah.\n",
    "<a href=\"https://hydroinformatics.byu.edu\" target=\"_blank\">BYU Hydroinformatics Lab</a>.</em></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook we will take a look at  a NetCDF (Network Common Data Form) file from the National Water Model (NWM) using a Python package called xarray. NetCDF files are a standardized way of exchanging scientific data. NetCDF is well suited for multidimensional datasets containing meteorological or observational data such as NWM forecasts. NetCDF can also contain a lot of useful metadata. Xarray is a Python package which is built on NumPy and pandas and works well with NetCDF. We will also explore more ways to visualize the national water model and learn a couple different ways to display its reaches on a map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em><h4>Imports</h4></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell installs or imports some Python modules or packages that will be used in this notebook. A brief explanation of what each one will be used for is provided below:\n",
    "* xarray makes it easier to work with multidimensional datasets like the NWM forecasts. \n",
    "* Importing the date type from the datetime module allows us to call todays date. \n",
    "* The os module allows us to communicate with the operating system. \n",
    "* Pandas is a useful library for data manipulation and analysis.\n",
    "* ipywidgets will be used to create a dropdown menu from which you can select a forecast type.\n",
    "* The requests module lets us make requests to web pages. \n",
    "* Matplotlib will help us create plots.\n",
    "* ipyleaflet is a package for creating interactive maps in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from datetime import date\n",
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import requests\n",
    "from requests import Request\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import ipyleaflet\n",
    "from ipyleaflet import Map, WMSLayer, basemaps, LayersControl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em><h4>Functions</em></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell should look familiar! It defines the functions that were used in the first sandbox. These functions build the appropriate url for a NWM forecast, get the NetCDF file stored at that url, and then build a time series of data for a given reach or stream. Remember, these forecasts are being retrieved from the NWM file server located at https://nomads.ncep.noaa.gov/pub/data/nccf/com/nwm/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetForecastFileName(ForecastStartDate = '20210321', ForecastStartTimestep='00', ForecastType = 'short_range', ForecastMember='1', TimeStep = '001'):\n",
    "  BaseName = 'https://nomads.ncep.noaa.gov/pub/data/nccf/com/nwm/prod/nwm.'\n",
    "\n",
    "  ForecastStartDate\n",
    "\n",
    "  if (ForecastType == 'short_range'):\n",
    "    return BaseName + ForecastStartDate + '/short_range/nwm.t' + ForecastStartTimestep +'z.short_range.channel_rt.f' + TimeStep + '.conus.nc'\n",
    "  elif (ForecastType == 'medium_range'): \n",
    "    return BaseName + ForecastStartDate + '/medium_range_mem' + ForecastMember + '/nwm.t' + ForecastStartTimestep +'z.medium_range.channel_rt_' + ForecastMember + '.f' + TimeStep + '.conus.nc'\n",
    "  elif (ForecastType == 'long_range'):\n",
    "    return BaseName + ForecastStartDate + '/long_range_mem' + ForecastMember + '/nwm.t' + ForecastStartTimestep +'z.long_range.channel_rt_' + ForecastMember + '.f' + TimeStep + '.conus.nc'\n",
    "  else:\n",
    "    return 'error'\n",
    "\n",
    "def GetForecastFile(Url = 'https://nomads.ncep.noaa.gov/pub/data/nccf/com/nwm/prod/nwm.20210321/short_range/nwm.t00z.short_range.channel_rt.f001.conus.nc'):\n",
    "  FileName = os.path.basename(Url)\n",
    "  if os.path.exists(FileName):\n",
    "    os.remove(FileName)\n",
    "  r = requests.get(Url, allow_redirects=True)\n",
    "  open(FileName, 'wb').write(r.content)\n",
    "  return FileName\n",
    "\n",
    "def GetSeries(StreamID = 23275226, ForecastStartDate = '20210321', ForecastStartTimestep='00', ForecastType = 'short_range', ForecastMember='1'):\n",
    "  TimeSteps = []\n",
    "  TimeSteps.clear()\n",
    "  Series = []\n",
    "  Series.clear()\n",
    "  if (ForecastType=='short_range'):\n",
    "    for i in range(18):\n",
    "      TimeSteps.append(\"%03d\" % (i+1))\n",
    "  elif (ForecastType=='medium_range' and ForecastMember=='1'):\n",
    "    for i in range(80):\n",
    "      TimeSteps.append(\"%03d\" % ((i+1)*3))\n",
    "  elif (ForecastType=='medium_range' and ForecastMember!='1'):\n",
    "    for i in range (68):\n",
    "      TimeSteps.append(\"%03d\" % ((i+1)*3))\n",
    "  elif (ForecastType=='long_range'):\n",
    "    for i in range(120):\n",
    "      TimeSteps.append(\"%03d\" % ((i+1)*6))\n",
    "  else: \n",
    "    return 'Error building time steps'\n",
    "  \n",
    "  for ts in TimeSteps:\n",
    "    MyUrl = GetForecastFileName(ForecastStartDate,ForecastStartTimestep, ForecastType,ForecastMember,ts)\n",
    "    FileName = GetForecastFile(MyUrl)\n",
    "    if(FileName != 'error'):\n",
    "      data = xr.open_dataset(FileName)\n",
    "      Q = float(data.sel(feature_id=StreamID).streamflow.values)\n",
    "      Series.append(Q)\n",
    "    else:\n",
    "      print('Error getting forecast files.')\n",
    "    \n",
    "  return Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em><h4>Variables</em></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's define some variables that we can use to download a forecast of our choice. Then we'll get the url and download the corresponding NetCDF forecast file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20210729\n"
     ]
    }
   ],
   "source": [
    "# These variables should look familiar to you from the first sandbox\n",
    "ForecastStart = '00'\n",
    "Type = 'short_range'\n",
    "Member = '1'\n",
    "Timestep = '001'\n",
    "today = date.today()\n",
    "today = str(today)\n",
    "today = today.replace(\"-\", \"\")\n",
    "print(today)\n",
    "\n",
    "# Build forecast url and get forecast file using the previously defined functions\n",
    "url = GetForecastFileName(today, ForecastStart,Type,Member,Timestep)\n",
    "path = GetForecastFile(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell creates a variable called 'ds' and assigns it a value of the given NetCDF file opened as an xarray dataset. That file was called in using a variable called 'path' which was defined in the previous cell. Take a look at the output of the next cell and try to learn a little bit about the metadata included with this dataset. You'll be able to see the different dataset dimensions, coordinates, variables, and attributes of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em><h4>xarray</em></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure><img src=\"images/xarray.png\" alt=\"null\" style=\"width: 350px;\"/></figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the NWM NetCDF file as an xarray dataset\n",
    "ds = xr.open_dataset(path)\n",
    "type(ds)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray has many useful options for dissecting and analyzing large multidimensional datasets such as NWM forecasts. It has great metadata support and is usually the best option when working with NetCDF. With xarray you're usually working with xarray datasets and datarrays. These are similar to pandas dataframes and dataseries but are better suited for multimdimensional data. The next few cells will walk you through a few things that xarray can do. For more information about xarray visit: http://xarray.pydata.org/en/stable/index.html.\n",
    "\n",
    "The image below is an example of a multidimensional dataset. Each cube inside of the large cube represents a single olympic medal. Each one of these medals belongs to one of three medal types (gold, silver, or bronze), as well as to one country (USA, China, or Great Britain), and the year in which the medal was won (2004, 2008, 2012). These 3 dimensions help describe each piece of data or each medal in the dataset.\n",
    "<figure><img src=\"images/Multidimensional.png\" alt=\"Shows a cube composed of smaller cubes representing Olympic medal winning countries. Cube layers are subdivided by dataset attributes. There are 3 dimensions. Country, medal type, and year.\" style=\"width: 350px;\"/></figure>\n",
    "\n",
    "NWM forecasts are multidimensional datasets as well. They consist of variables or data with 3 dimensions and many attributes. Let's take a closer look at the way these forecasts are organized and what sort of things we can do with them in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's separate out the variables of our dataset into a dictionary of corresponding DataArray objects.\n",
    "vars_dict = ds.data_vars\n",
    "print(vars_dict)\n",
    "type(vars_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also separate out the coordinates of the dataset into a dictionary of corresponding DataArray objects.\n",
    "coords_dict = ds.coords\n",
    "print(coords_dict)\n",
    "type(coords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And you can separate out the attributes of a dataset into a dictionary of corresponding DataArray objects.\n",
    "attrs_dict = ds.attrs\n",
    "print(attrs_dict)\n",
    "type(attrs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's extract the streamflow values from the dataset as a dataarray\n",
    "da = ds[\"streamflow\"]\n",
    "print(type(da))\n",
    "print(da)\n",
    "\n",
    "# How many streamflow values are there?\n",
    "len(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try sorting the streamflow values in descending order and then dropping any null values. Now we can see the array is sorted from largest streamflow value to smallest.\n",
    "da = da.sortby(da, False)\n",
    "da = da.dropna('feature_id')\n",
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract the largest flow, assign it to a value called 'largest_flow', and convert it to a float\n",
    "largest_flow = da[0]\n",
    "largest_flow = float(largest_flow)\n",
    "print(type(largest_flow))\n",
    "print(largest_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next it would be cool to find the feature_id associated with the largest streamflow value. \n",
    "# First let's convert our xarray dataset to a pandas dataframe.\n",
    "df = ds.to_dataframe()\n",
    "print(type(df))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create a mask of the dataframe where streamflow is equal to 'largest_flow'\n",
    "# Then we can filter our dataframe using the mask to find the feature_id and other metadata associated with the largest flow.\n",
    "df_mask = df['streamflow']==largest_flow\n",
    "filtered_df = df[df_mask]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray and pandas are both great tools for using and analyzing NWM data. Hopefully you are beginning to see how these tools can be used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em><h4>Plot</em></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to visualize the original 'ds' dataset using matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8,6)\n",
    "ds.streamflow.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That plot isn't great. Because each NetCDF file contains a certain forecast (short, medium, long, etc.) at a certain time for the entire NWM network (every single reach covered by the NWM), the plot is displaying Reach IDs on the x axis and streamflow on the y. This isn't very helpful. Instead of plotting our xarray dataset, let's try instead to create a map that will display all of the NWM reaches and let us see some of their attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em><h4>Mapping</em></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we should define some variables that will help us create our map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoom level\n",
    "zoom = 4\n",
    "# lat and long coordinates for the center of the map\n",
    "center = (39,-96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to create the map with ipyleaflet and then add a WMS layer too it. WMS (Web Map Services) allows us to pull in data that is stored somewhere on the web. In this case the data is coming from a shapefile stored in a Hydroshare resource. Hydroshare is a web based hydrologic information system for sharing and publishing hydrologic data. The shapefile was created from a geodatabase of the entire NWM network, obtained from the NWM website here: https://water.noaa.gov/about/nwm. In this case we are only pulling in one layer which contains the NWM reaches lying inside of Hydrologic Unit Code (HUC) number 1. The Hydroshare resource id is 'HS-f5fa9306f92147918fc500c386cf0dd9' and the shapefile is named 'HUC1'. \n",
    "\n",
    "The resource is located here: https://www.hydroshare.org/resource/f5fa9306f92147918fc500c386cf0dd9/. \n",
    "\n",
    "That particular resource only contains a few HUCs. There are 18 in total. These 18 HUCs essentially represent 18 very large watersheds which cover the entire continental United States. You can learn more about that here if you wish: https://www.usgs.gov/core-science-systems/ngp/national-hydrography/watershed-boundary-dataset?qt-science_support_page_related_con=4#qt-science_support_page_related_con.\n",
    "\n",
    "<figure><img src=\"images/HUCs.png\" alt=\"HUC Boundaries\" style=\"width: 350px;\"/><figcaption>Hydrologic Unit Code Boundaries</figcaption></figure>\n",
    "\n",
    "Several Hydroshare resources make up a collection which contains all of the NWM reaches divided up by HUC. This collection was created so that the NWM reaches could be pulled onto web maps via the WMS url that Hydroshare generates for its resources. The entire collection can be found here: https://www.hydroshare.org/resource/c16596e525bf41e2ae843f1e3bbcef90/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map called 'mappy' with a basemap, and the zoom level and center that we defined previously.\n",
    "mappy = Map(basemap=basemaps.CartoDB.Positron, center=center, zoom=zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a WMS Layer from the desired Hydroshare resource and desired layer (shapefile).\n",
    "wmslay = WMSLayer(\n",
    "    url = 'https://geoserver.hydroshare.org/geoserver/HS-f5fa9306f92147918fc500c386cf0dd9/wms?',\n",
    "    layers = 'HS-f5fa9306f92147918fc500c386cf0dd9:HUC1',\n",
    "    transparent=True,\n",
    "    name = 'HUC1',\n",
    "    format = 'image/png'\n",
    ")\n",
    "\n",
    "# Create a layers control at the top right of the map\n",
    "control = LayersControl(position='topright')\n",
    "\n",
    "# Add the layers control to 'mappy'\n",
    "mappy.add_control(control)\n",
    "\n",
    "# Add the WMS Layer to 'mappy'\n",
    "mappy.add_layer(wmslay)\n",
    "\n",
    "mappy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That map shows all of the NWM reaches in HUC1, but we haven't actually done anything which would allow us to get a reach's reach id or view the forecasts yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to use some Jupyter notebook magic to run HTML and display a JavaScript web map. What you see in the next cell is HTML. All it is really doing is displaying the web page at https://byu-hydroinformatics.github.io/csb-jr233/. \n",
    "\n",
    "The web page was built using javascript to display all of the NWM reaches on a map and provide their attributes when features are clicked on. It uses a WMS layer (separate from the ones mentioned above) which contains all of the NWM Reaches and is built using OpenLayers which is a JavaScript library for mapping. \n",
    "\n",
    "Zooming into a specific part of the map will prompt the reaches to appear. By clicking on a specific reach you can then obtain its reach id. Be careful, the reach id in this dataset is called a 'station_id'. If you accidentally enter in another value or identifier as your reach id further down, the successive code cells won't work.\n",
    "\n",
    "The source code for this map and web page can be found here: https://github.com/BYU-Hydroinformatics/NWM_Map_Sandbox2. It consists of several files of code, but the important stuff is primarily in the main.js file. In less than 100 lines of code you could create a similar map yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<html>\n",
    "<head></head>\n",
    "<body>\n",
    "<iframe title=\"NWM Reaches\" src=\"https://byu-hydroinformatics.github.io/csb-jr233/\" width=900 height=600>\n",
    "</iframe>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you've had a chance to play around and obtain an object id for a stream of interest, run the next cell and enter in the reach id (station_id) when prompted. Make sure you are getting the 'station_id' value and not the 'OBJECTID'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this cell will prompt the user to enter in a value which will then be assigned to the variable 'reach'\n",
    "reach = input(\"Reach/Stream/Feature ID: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'reach' from string type to integer type\n",
    "reach = int(reach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use ipywidgets to create a menu dropdown with options for the NWM forecast types.\n",
    "menu = widgets.Dropdown(\n",
    "       options=['short_range', 'medium_range', 'long_range'],\n",
    "       value='short_range',\n",
    "       description='Forecast:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will display the menu that we created in the last cell. Select your desired forecast from it.\n",
    "menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets build a time series for the reach you entered and the forecast type selected from 'menu'.\n",
    "Series = GetSeries(reach, today, '00', menu.value, '1')\n",
    "print(Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create a plot of the forecast like we did in the first sandbox.\n",
    "plt.rc('font', size=14)\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(Series, color='tab:blue', label='Streamflow')\n",
    "ax.set_xlabel('Time (hours)')\n",
    "ax.set_ylabel('Flowrate (cms)')\n",
    "ax.set_title(menu.value + ' forecast for Stream ID ' + str(reach))\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool right! We can build a map to display the NWM network, display the map here in our Jupyter notebook, obtain a reach id from it, and then plot its forecast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly we'll erase any nwm files leftover in our Jupyter notebook's file browser.\n",
    "files = [f for f in os.listdir('.') \n",
    "         if os.path.isfile(f)]\n",
    "\n",
    "for f in files:\n",
    "    # Look at every file and if contains 'nwm' then remove/delete it! \n",
    "    if \"nwm\" in f:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em><h4>Exercises</h4></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part of this notebook asks you to try a few things for yourself. Do your best to complete the 4 exercises below or answer the given questions by using what you've learned here. Feel free to add new cells to run any code that you might need to answer a question or complete a task. It may also be a good idea to run the previous cell after each exercise to delete excess files so that your Jupyter notebook's file browser doesn't fill up. \n",
    "1. Extract the river velocity values as a DataArray from the xarray Dataset that we used earlier. What units are these values in? Which reach id corresponds to the largest velocity in the array?\n",
    "\n",
    "2. You may have noticed that each feature or reach in the NWM has a variety of metadata attributes including one called StreamOrder. There are several methods for assigning stream order. You can read about two of them at this link: https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-analyst/how-stream-order-works.htm. Now try to determine which method the NWM uses to order its streams by interacting with the JavaScript map above. Is it the Strahler or the Shreve method? \n",
    "\n",
    "<figure><img src=\"images/Strahler.png\" alt=\"Strahler Method\" style=\"width: 200px;\"/><figcaption>Strahler Method</figcaption></figure>\n",
    "<figure><img src=\"images/Shreve.png\" alt=\"Shreve Method\" style=\"width: 200px;\"/><figcaption>Shreve Method</figcaption></figure>\n",
    "\n",
    "3. Create an ipyleaflet map which displays all of the NWM reaches in Hydrologic Unit Code 2. The shapefile for HUC2 is located in the same resource as HUC1. Also change the zoom level and latitude and longitude coordinates for the center of the map so that the reaches in HUC2 are centered and zoomed in upon. You should be able to do this by editing the code for the ipyleaflet WMS map above (not the JavaScript map). It should wind up looking something like this: <figure><img src=\"images/HUC2.png\" alt=\"NWM Reaches in HUC 2\" style=\"width: 350px;\"/><figcaption>NWM Reaches in HUC 2</figcaption></figure>\n",
    "\n",
    "4. Using the NWM JavaScript map above, obtain reach ids for 3 streams of stream order 1, 3 streams of stream order 2, and 3 streams of stream order 3. Try to pick streams that are relatively close to each other. Build a time series for each one's medium range forecast from yesterday using the functions in this notebook. Find the high flow for each of the 9 streams in its respective medium range time series and compare to the other streams. Do your results make sense? Do the higher order streams have larger high flows? What is the reach id of the stream with the highest flow in order 3? Where would you expect to find that reach or stream? HINT: When building the time series, make sure that you are requesting the medium_range forecast and that you've formatted the forecast start date like this: \"YYYYMMDD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for using this resource! Hopefully this exercise has helped open your eyes to what can be done to analyze NWM forecasts and create maps and plots of the NWM network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
